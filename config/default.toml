# Default configuration for the Web Crawler & Search Engine

[crawler]
# Maximum number of concurrent HTTP requests
max_concurrent_requests = 100

# Maximum crawl depth from the seed URL
max_depth = 5

# HTTP request timeout in seconds
timeout_seconds = 30

# User agent string for HTTP requests
user_agent = "RustCrawler/0.1.0 (+https://github.com/yourusername/crawler)"

# Default delay between requests to the same domain (milliseconds)
default_delay_ms = 1000

# Maximum number of retries for failed requests
max_retries = 3

# Maximum page size in bytes (10MB)
max_page_size = 10485760

# Number of crawler worker threads
num_workers = 8

[storage]
# PostgreSQL database URL
database_url = "postgres://crawler:password@localhost/webcrawler"

# Maximum database connections
max_connections = 10

# Directory path for the search index
index_path = "./data/index"

[search]
# Maximum number of search results
max_results = 1000

# Default number of results per page
default_limit = 10

# Enable search result snippets
enable_snippets = true

# Length of search result snippets (characters)
snippet_length = 200

[api]
# API server host
host = "127.0.0.1"

# API server port
port = 8080

# Enable CORS for web frontends
enable_cors = true

# API rate limit (requests per minute per IP)
rate_limit = 100